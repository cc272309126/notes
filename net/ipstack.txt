ipstack


http://blog.csdn.net/zhangskd/article/details/22079509

http://blog.chinaunix.net/uid-24148050-id-464587.html

http://blog.chinaunix.net/uid-20795129-id-469821.html


分析数据在协议栈底层的流程:  
    
当网卡收到数据后，产生硬件中断，由中断处理程序（一般为网卡驱动程序所注册）从网卡内读取数据，并封装称sk_buff{}结构，然后把这些数据传递给函数netif_rx（）进行进一步的处理。   
函数netif_rx（）根据当前接收队列的拥挤情况，选择丢弃还是接收，如果是接收，则将接收到的sk_buff{}挂到接收队列softnet_data[CPU]->input_pkt_queue上，并调用函数__cpu_raise_softirq（）激活软中断NET_RX_SOFTIRQ，相应的处理函数是net_rx_action（）。   
在函数net_rx_action（）中根据数据包的协议类型，调用相应的处理函数。对于IP包，处理函数是ip_rcv（）。   
函数ip_rcv（）对IP包进行了一系列必要的检查（包括检查校验和），最终调用函数ip_rcv_finish（）对数据包进行向上传输。   
函数ip_rcv_finish（）首先调用函数ip_route_input（）获取路由，检测该包是发给本机的还是要进行转发的，如果要进行转发，则调用调用函数ip_forward（）进行转发，否则调用函数ip_local_deliver（）进一步向上传递数据包。   
函数ip_local_deliver（）首先进行了防火墙的过滤工作，最终调用函数ip_local_deliver_finish（）向上传递数据。   
在函数ip_local_deliver_finish（）中，会检查是否有匹配协议（如根据IP头判断我们的数据包是TCP包，则要判断是否有接收TCP包的原始套接口。当然，如果有接收所有IP包的原始套接口存在也是可以的）的原始套接口。如果有，则调用函数raw_v4_input（）进行处理。   
在函数raw_v4_input（）中，要进一步进行匹配，这次匹配的依据有四个，依次是：协议、源地址、目的地址和接收接口。分别对每一个匹配成功的原始套接口调用函数raw_rcv（）传递一个克隆的以sk_buff{}为结构的数据包。   
接下来的几个函数都很简单，调用顺序依次是raw_rcv（）、raw_rcv_skb（）和sock_queue_rcv_skb（）。这几个函数基本上都是简单的依次调用关系。最后调用函数sock_queue_rcv_skb（），该函数经过skb_queue_tail（）函数将数据包sk_buff{}放入了接收队列sk->receive_queue的末尾。 


网卡概述
 
(1) 网卡收包
网线上的物理帧首先被网卡芯片获取，网卡芯片会检查物理帧的CRC，保证完整性。
然后网卡芯片将物理帧头去掉，得到MAC包。
网卡芯片会检查MAC包内的目的MAC地址，如果和本网卡的MAC地址不一样则丢弃(混杂模式除外)。
之后网卡芯片将MAC帧拷贝到网卡内部的缓冲区，触发硬中断。
网卡的驱动程序通过硬中断处理函数，构建sk_buff，把它拷贝到内存中，接下来交给内核处理。
在这个过程中，网卡芯片对物理帧进行了MAC匹配过滤，以减小系统负荷。
 
(2) 网卡发包
网卡驱动程序将IP包添加14字节的MAC头，构成MAC包。
MAC包中含有发送端和接收端的MAC地址，由于是驱动程序创建MAC头，所以可以随便输入地址
进行主机伪装。
驱动程序将MAC包拷贝到网卡芯片内部的缓冲区，接下来由网卡芯片处理。
网卡芯片将MAC包再次封装为物理帧，添加头部同步信息和CRC校验，然后丢到网线上，就完成
一个IP报的发送了，所有接到网线上的网卡都可以看到该物理帧。

(3) 网卡数据结构
网卡用net_device来表示，用register_netdevice()注册到系统中，注册过的网卡可以通过
unregister_netdevice()注销掉。


1: physical layer

物理网卡收到包
    -- CRC check
    -- remove physical header, get the MAC package
    -- check mac address (discard mac packge if mac address is not myself)
    -- copy mac package into netcard memory buffer
    -- generate interrupt

2: link layer  -- driver -- package from netcard buffer to kernel memory

link layer总体流程
中断
1 分配sk_buff
2 copy mac package into sk_buff
3 判断net layer层的协议类型，根据类型进行处理，当前基本上是IP报文
    3.1 cpu_softnet_data 队列满，拥塞丢弃
    3.2 入队到末尾
    3.3 调用NAPI，产生soft interrupt NET_RX_SOFTIRQ 在net_rx_action处理
        3.3.1 net_rx_action
        3.3.2 根据L2报文标志 处理link layer的业务，比如vlan, bridge 
        3.3.3 根据L3报文类型 选择对应的向上交互函数，对于IPv4报文，是ip_rcv （IPv6, pppoe）


网卡用net_device来表示，用register_netdevice()注册到系统中，注册过的网卡可以通过unregister_netdevice()注销掉。

3c501网卡驱动为例
/* 3c501.c: A 3Com 3c501 Ethernet driver for Linux. */
drivers/net/3c501.c
drivers/net/3c501.h

el1_probe
    el1_probe1
        dev->open = &el_open;
        dev->hard_start_xmit = &el_start_xmit;

el_open
    request_irq(dev->irq, &el_interrupt, 0, dev->name, dev)

el_interrupt
    el_receive -- 各种判断 直到 el_receive
        -- dev_alloc_skb  ; alloc sk_buff /* 申请一个skb，2字节用于对齐IP */
            -- insb(DATAPORT, skb_put(skb,pkt_len), pkt_len); /* 扩展skb的data room，并把网卡缓存的数据包拷贝到skb->data中 */  
        -- eth_type_trans  - determine the packet's protocol ID.  PACKET_BROADCAST/PACKET_MULTICAST/IP /* 使用哪种三层协议，一般是IP协议 */  
        -- netif_rx(skb); /* 旧的接收处理函数   目前多数网卡支持新的接口NAPI */
    
netif_rx()主要调用enqueue_to_backlog()进行后续处理。
softnet_data 每个cpu都有一个softnet_data实例，用于收发数据包。  

netif_rx 
netif_rx()是内核接收网络数据包的入口（目前多数网卡支持新的接口NAPI）。
netif_rx()主要调用enqueue_to_backlog()进行后续处理。

接收数据包的上半部处理流程为：
el_interrupt() // 网卡驱动
    |--> el_receive() // 网卡驱动
                |--> netif_rx() // 内核接口
                           |--> enqueue_to_backlog() // 内核接口

接收数据包的下半部处理流程为：
net_rx_action // 软中断
    |--> process_backlog() // 默认poll
               |--> __netif_receive_skb() // L2处理函数
                            |--> ip_rcv() // L3入口                        
                           
/**
 *  netif_rx    -   post buffer to the network code
 *  @skb: buffer to post
 *
 *  This function receives a packet from a device driver and queues it for
 *  the upper (protocol) levels to process.  It always succeeds. The buffer
 *  may be dropped during processing for congestion control or by the
 *  protocol layers.
 *
 *  return values:
 *  NET_RX_SUCCESS  (no congestion)
 *  NET_RX_DROP     (packet was dropped)
 *
 */     
netif_rx
    -- 队列满，拥塞，丢弃
    -- 不满 （queue = &__get_cpu_var(softnet_data);）
        __skb_queue_tail(&queue->input_pkt_queue, skb);
        napi_schedule(&queue->backlog);
            __napi_schedule
                __raise_softirq_irqoff(NET_RX_SOFTIRQ);
                    open_softirq(NET_RX_SOFTIRQ, net_rx_action, NULL);
                    
                    
net_rx_action
    struct napi_struct->poll == process_backlog
        netif_receive_skb ==> 处理链路层业务，比如vlan, bridge
            deliver_skb
                struct packet_type->func == ip_rcv (如果是IPv4报文， 还有IPv6, pppoes, pppoed, ...)
            
/*
 *  IP protocol layer initialiser
 */
static struct packet_type ip_packet_type = {
    .type = __constant_htons(ETH_P_IP),
    .func = ip_rcv,
    .gso_send_check = inet_gso_send_check,
    .gso_segment = inet_gso_segment,
};
static struct packet_type ipv6_packet_type = {
    .type = __constant_htons(ETH_P_IPV6),
    .func = ipv6_rcv,
    .gso_send_check = ipv6_gso_send_check,
    .gso_segment = ipv6_gso_segment,
};
static struct packet_type pppoes_ptype = {
    .type   = __constant_htons(ETH_P_PPP_SES),
    .func   = pppoe_rcv,
};
static struct packet_type pppoed_ptype = {
    .type   = __constant_htons(ETH_P_PPP_DISC),
    .func   = pppoe_disc_rcv,
};

            

/*
 * Incoming packets are placed on per-cpu queues so that
 * no locking is needed.
 */
每个cpu都有一个softnet_data实例，用于收发数据包。 
struct softnet_data
{
    struct net_device   *output_queue; /* 输出包队列 */  
    struct sk_buff_head input_pkt_queue; /* 输入队列，保存接收到的数据包。  非NAPI使用，支持NAPI的网卡驱动有自己的私有队列。  */    
    struct list_head    poll_list;  /* 其中设备是处于轮询状态的，即入口队列有新的帧等待处理 */  
    struct sk_buff      *completion_queue; /* 成功传输的数据包队列 */  
    struct napi_struct  backlog; /* 虚拟设备 或者 非NAPI设备 两者共用 */  
};
DECLARE_PER_CPU(struct softnet_data,softnet_data);
    
net_dev_init
    queue->backlog.poll = process_backlog;  /* 非NAPI的默认轮询函数 */  
    queue->backlog.weight = weight_p;   /* 64，每次轮询处理数据包个数上限 */    
    open_softirq(NET_TX_SOFTIRQ, net_tx_action, NULL);
    open_softirq(NET_RX_SOFTIRQ, net_rx_action, NULL);  
    
    
3: network layer

IP报头：
struct iphdr {
#if defined(__LITTLE_ENDIAN_BITFIELD)
    __u8 ihl:4,
         version:4;
#elif defined(__BIG_ENDIAN_BITFIELD)
    __u8 version:4, /* 协议版本，IPv4为4 */
         ihl:4; /* 首部长度，不包括选项为5，表示20字节 */
#else
#error "Please fix <asm/byteorder.h>"
#endif

    __u8 tos; /* TOS服务类型，6位DSCP，2为ECN */
    __be16 tot_len; /* IP包总长度，最大为65535 */
    __be16 id; /* 标识符，同一个IP包的不同分片具有相同的标识符 */
    __be16 frag_off; /* 3个标志位，13位偏移 */
    __u8 ttl; /* 存活时间，一般为64跳 */
    __u8 protocol; /* L4协议值 */
    __sum16 check; /* 报头校验和，不包含载荷 */
    __be32 saddr; /* 源IP */
    __be32 daddr; /* 目的IP */
}; 

ip_rcv()是IP层的入口，主要做了：
丢弃L2目的地址不是本机的数据包（这说明网卡处于混杂模式，嗅探器会处理这些包）。
检查skb的引用计数，如果大于1，说明其它地方也在使用此skb，则克隆一个skb返回；否则直接返回原来的skb。
数据包合法性检查：
data room必须大于IP报头长度。
IP报头长度至少是20，类型为IPv4。
data room至少能容纳IP报头(包括IP选项)。
检查IP报头校验和是否正确。
数据包没被截断(skb->len >= 报总长)，报总长不小于20。
如果L2有进行填充（以太网帧最小长度为64），则把IP包裁剪成原大小，去除填充。此时如果接收的NIC
已计算出校验和，则让其失效，让L4自己重新计算。
最后，调用netfilter的NF_INET_PRE_ROUTING的钩子函数，如果此数据包被钩子函数放行，则调用
ip_rcv_finish()继续处理。

ip_rcv_finish()主要做了：
查找路由，决定要把数据包发送到哪，赋值skb_dst()->input()，发往本地为ip_local_deliver，转发为ip_forward()。
更新Traffic Control (Qos)层的统计数据。
处理IP选项，检查选项是否正确，然后将选项存储在IPCB(skb)->opt中。
最后执行skb_dst()->input()，要么发往四层，要么进行转发，取决于IP的目的地址。

ip_rcv_finish
    -- ip_route_input 查找路由，决定包的类型是本地还是route， 同时决定报文的发送函数 
        -- rt_hash_table 从缓存hash table中查找，找到直接赋值
        -- ip_route_input_slow 没有从hash table找到，重新组装
            -- fib_lookup， 从fib查找， fib实际上是route table, routetable实际赏识 fib cache, 因此类似tlb机制
                -- 类型是RTN_LOCAL
                    rth->u.dst.output= ip_rt_bug;
                    rth->u.dst.input= ip_local_deliver;
                -- 类型是网路转发 == ip_mkroute_input
                    -- __mkroute_input
                        rth->u.dst.input = ip_forward;
                        rth->u.dst.output = ip_output;
                    -- 创建hash table entry
    -- dst_input 发送报文 
        struct sk_buff->dst->input(skb);


在ip_local_deliver()中，如果发现数据报有被分片，则进行组装。
然后调用NF_INET_LOCAL_IN处的钩子函数，如果数据包被钩子函数放行，
则调用ip_local_deliver_finish()继续处理。

ip_local_deliver
    -- 分片，则分片组装
    -- NF_HOOK(PF_INET, NF_IP_LOCAL_IN, skb, skb->dev, NULL, ip_local_deliver_finish);

ip_local_deliver_finish()主要做了：
处理RAW IP，如果有配置安全策略，则进行IPsec安全检查。
根据IP报头的protocol字段，找到对应的L4协议(net_protocol)，调用该协议的接收函数net_protocol->handler()。
对于TCP协议，net_protocol实例为tcp_protocol，协议处理函数为tcp_v4_rcv()。
接下来就进入四层协议的处理流程了，TCP协议的入口函数为tcp_v4_rcv()。

ip_local_deliver_finish
    -- rawIP, 则有ipsec, vpn等相关业务
    -- 根据protocol type, 调用对应的上传函数，交互给上层
        struct net_protocol->handler(skb); == tcp_v4_rcv/udp_rcv/icmp_rcv
            

数据包从L2传递到L3时，通过packet_type结构来找到L3协议的处理函数。
同理，数据包从L3传递到L4时，通过net_protocol结构来找到L4协议的处理函数。

ip_forward
    -- 减少 ttl
    -- NF_HOOK(PF_INET, NF_IP_FORWARD, skb, skb->dev, rt->u.dst.dev, ip_forward_finish);
        -- dst_output
            struct sk_buff->dst->output(skb); == ip_output
                NF_HOOK_COND(PF_INET, NF_IP_POST_ROUTING, skb, NULL, dev,ip_finish_output, !(IPCB(skb)->flags & IPSKB_REROUTED));
                    -- 分片
                    -- ip_finish_output2
                        --struct dst_entry->neighbour->output(skb); 

static struct net_protocol igmp_protocol = {
    .handler =  igmp_rcv,
};
static struct net_protocol tcp_protocol = {
    .handler =  tcp_v4_rcv,
    .err_handler =  tcp_v4_err,
    .gso_send_check = tcp_v4_gso_send_check,
    .gso_segment =  tcp_tso_segment,
    .no_policy =    1,
};
static struct net_protocol udp_protocol = {
    .handler =  udp_rcv,
    .err_handler =  udp_err,
    .no_policy =    1,
};
static struct net_protocol icmp_protocol = {
    .handler =  icmp_rcv,
};


enum nf_inet_hooks {
    NF_INET_PRE_ROUTING, -- 进入了IP层， 查找目的地之前
    NF_INET_LOCAL_IN, -- 本地报文处理ip header之前
    NF_INET_FORWARD, -- 转发报文
    NF_INET_LOCAL_OUT, -- 从传输层到ip层
    NF_INET_POST_ROUTING, -- 从ip层转发之前
    NF_INET_NUMHOOKS
};



ip_rcv
1: 处理ip header相关业务，调用ip_rcv_finish
2: ip_rcv_finish查找路由，决定向上传送，还是传给网络


ip_rcv
    -- IP header 业务
    -- NF_HOOK(PF_INET, NF_IP_PRE_ROUTING, skb, dev, NULL, ip_rcv_finish); == ip_rcv_finish
        -- 查询目的地，决定转发类型
            -- 先查询hash_table cache
            -- 再查询fib
                -- 先查询fib cache (== route table)
                -- 再创建 route table entry , insert into fib
            -- 目的地是local ip_local_deliver
            -- 目的地是network, ip_forward
        -- 根据类型转发
            -- ip_local_deliver 本地
                -- 分片，则组装
                -- NF_HOOK(PF_INET, NF_IP_LOCAL_IN, skb, skb->dev, NULL, ip_local_deliver_finish);
                    -- 处理rawIP 相关业务 （ipsec, vpn）
                    -- 根据protocol type,交互给上层 tcp_v4_rcv/udp_rcv/icmp_rcv
            -- ip_forward
                -- 减少ttl
                --  NF_HOOK(PF_INET, NF_IP_FORWARD, skb, skb->dev, rt->u.dst.dev, ip_forward_finish);
                    -- NF_HOOK_COND(PF_INET, NF_IP_POST_ROUTING, skb, NULL, dev,ip_finish_output, !(IPCB(skb)->flags & IPSKB_REROUTED));
                        -- 分片
                        -- ip_finish_output2
                            --struct dst_entry->neighbour->output(skb); 
                            
                            

                            
                            
